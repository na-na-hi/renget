# The 'Ayumi' Inofficial LLM ERP Model Rating

This rating table contains a rating of different LLMs that tries to determine which model is most suitable for erotic role playing (ERP).

***
[TOC]
***

The rating was done using rather primitive scripts and techniques, so don't expect this to be a deeply scientific rating. They are also all
based on a single character ('Ayumi') and a single fixed erotic setting. What is counted are the number of lewd words that were generated by the model. A few details about the testing procedure can be found further down.

!!! danger Interpretation warning
    Please take this rating with a spoon of salt. It tests just **one scene in one setting with one character** and analyses the words of the result. It does not evaluate creative writing capabilities. Do your own tests for your use cases. General advice: 13B models give overall more sensible and coherent output. 7B models sometimes need more hand holding to get sensible and coherent output, they are also more picky regarding the prompt format. The 3B models I tested have maybe a good rating here, but they usually barely recognize the overall setting or context of the conversation.

## LLM Models ERP Ranking

Date: 2023-06-08 V18

Complete:

| Rank | Model                    |   B | Qnt   | Prompt Format  | Temperature |  ERP Score |  Word IQ | Words | Long Words |
|------:|--------------------------|-----|-------|----------------|-------------:|------------:|----------:|-------:|------------:|
|    1 | WizardLM UC SCOT ST 30B  | 30B | Q4_0  | alpaca         |         0.9 |  🌟 12.2 | 🔵 22.9 | 🔵 60.0 |  🔵 34.9 |
|    2 | Chronos WizLM UC SCOT ST 13B | 13B | Q4_0  | alpaca         |         0.7 |  🌟 12.2 | 🔵 27.3 | 🔵 52.8 |  🔵 30.8 |
|    3 | Wizard Vicuna Uncens 30B | 30B | Q4_0  | vicuna11st     |         0.7 |  🌟 12.2 |     20.4 | 🔵 50.0 |  🔵 28.9 |
|    4 | Chronos 13B              | 13B | Q4_0  | alpaca         |         0.7 |   ⭐ 11.6 | 🔵 28.2 | 🔵 53.5 |  🔵 31.1 |
|    5 | LLaMA SCOT 13B           | 13B | Q5_1  | vicuna         |         0.9 |   ⭐ 11.0 |     18.1 |  41.0 |  🔵 23.4 |
|    6 | Airoboros GPT4 7B        |  7B | Q4_0  | alpaca         |         0.7 |   ⭐ 10.8 | 🔵 24.9 |  42.0 |  🔵 24.6 |
|    7 | Guanaco 13B              | 13B | Q5_1  | vicuna11st     |         0.7 |   ⭐ 10.8 |     18.7 | 🔵 46.6 |  🔵 24.9 |
|    8 | Nous Hermes 13B          | 13B | Q4_0  | vicuna         |         0.7 |    ⭐ 9.6 |     18.1 |  38.4 |       23.0 |
|    9 | Wizard Vicuna Uncens 13B | 13B | Q8_0  | metharme       |         0.7 |    ⭐ 9.0 | 🔴 17.3 |  36.0 |       19.6 |
|   10 | RedPajama 0.1 Instruct 7B |  7B | Q5_1  | vicuna11       |         0.7 |    ⭐ 8.8 |     21.5 | 🔵 50.6 |  🔵 28.3 |
|   11 | Alpacino SCOT 13B        | 13B | Q4_0  | vicuna         |         0.7 |    ⭐ 8.6 |     20.1 |  35.1 |       19.1 |
|   12 | Wizard Vicuna Uncens 7B  |  7B | Q4_0  | metharme       |         0.7 |    ⭐ 8.1 | 🔵 22.6 | 🔴 31.1 |       18.0 |
|   13 | HyperMantis 13B          | 13B | Q5_1  | vicuna         |         0.7 |    ⭐ 8.0 | 🔴 15.6 | 🔴 30.4 |  🔴 16.8 |
|   14 | Wizard Vicuna Uncens 13B | 13B | Q5_1  | pygmalion      |         0.9 |        7.8 |     19.6 |  31.2 |       17.9 |
|   15 | Airoboros 7B             |  7B | Q4_0  | alpaca         |         0.7 |        7.7 | 🔵 28.5 |  36.4 |       20.4 |
|   16 | RedPajama Instruct 3B    |  3B | Q4_0  | alpaca         |         0.7 |        7.0 |     20.0 | 🔵 51.0 |  🔵 28.2 |
|   17 | GPT4 x Vicuna 13B        | 13B | Q4_1  | vicuna         |         0.9 |        6.5 | 🔵 22.0 | 🔵 43.9 |  🔵 24.2 |
|   18 | Wizard Mega 13B          | 13B | Q8_0  | pygmalion      |         0.9 |        6.2 |     18.7 |  39.0 |       20.9 |
|   19 | Based 7B                 |  7B | Q4_0  | metharme       |         0.7 |        6.2 | 🔴 13.2 | 🔴 24.7 |  🔴 13.6 |
|   20 | Pygmalion 7B             |  7B | Q8_0  | vicuna11       |         0.9 |        6.2 |     19.7 | 🔵 50.6 |  🔵 28.1 |
|   21 | GPT4 x Vicuna 13B        | 13B | Q5_1  | vicuna         |         0.9 |        6.2 |     19.7 |  39.4 |       21.4 |
|   22 | Guanaco 7B               |  7B | Q5_1  | alpaca         |         0.7 |        6.2 | 🔵 22.5 |  33.6 |       17.4 |
|   23 | LLaMA 13B                | 13B | Q8_0  | vicuna11st     |         0.7 |        6.1 | 🔴 17.2 | 🔴 30.1 |  🔴 16.8 |
|   24 | LLaMA Deus 7B            |  7B | Q5_1  | vicuna11       |         0.7 |        6.0 | 🔴 16.5 |  32.5 |       18.1 |
|   25 | Manticore Guanaco 13B    | 13B | Q4_0  | metharme       |         0.7 |        6.0 |     20.5 | 🔵 48.0 |  🔵 25.5 |
|   26 | LLaMA 7B                 |  7B | Q4_0  | metharme       |         0.7 |        6.0 | 🔴 13.0 |  31.4 |  🔴 16.7 |
|   27 | Planner 7B               |  7B | Q4_0  | metharme       |         0.7 |        6.0 | 🔴 13.0 |  31.4 |  🔴 16.7 |
|   28 | LLaMA 7B                 |  7B | Q8_0  | vicuna11       |         0.9 |        5.8 |     19.2 |  40.7 |       21.7 |
|   29 | GPT4All Snoozy 13B       | 13B | Q4_0  | vicuna         |         0.7 |        5.5 | 🔴 17.7 |  35.5 |       18.6 |
|   30 | Metharme 7B              |  7B | Q4_1  | metharme       |         0.9 |        5.3 |     19.1 |  38.3 |       21.1 |
|   31 | Metharme 7B              |  7B | Q5_1  | vicuna11st     |         0.9 |        5.2 |     20.9 |  39.4 |       22.1 |
|   32 | OpenLLaMA 700bt 7B       |  7B | Q5_1  | vicuna         |         0.9 |        5.0 |     21.5 | 🔴 26.2 |  🔴 14.4 |
|   33 | Pygmalion 7B             |  7B | Q5_1  | vicuna         |         0.7 |        5.0 |     19.4 |  39.8 |       20.1 |
|   34 | RedPajama Instruct 7B    |  7B | Q4_0  | vicuna11       |         0.7 |        5.0 | 🔴 16.4 |  36.0 |       19.1 |
|   35 | Baize V2 13B             | 13B | Q4_1  | vicuna11       |         0.9 |        5.0 |     21.1 |  34.3 |       17.9 |
|   36 | Guanaco 7B               |  7B | Q4_0  | metharme       |         0.9 |        4.8 | 🔵 23.3 | 🔴 21.4 |  🔴 12.2 |
|   37 | Wizard Mega 13B          | 13B | Q4_0  | pygmalion      |         0.7 |        4.8 |     18.4 | 🔵 45.6 |       22.7 |
|   38 | LLaMA 13B                | 13B | Q4_0  | vicuna         |         0.7 |        4.7 | 🔴 15.3 | 🔴 29.7 |  🔴 16.1 |
|   39 | Wizard Mega 13B          | 13B | Q5_1  | vicuna         |         0.7 |        4.6 |     21.1 | 🔴 25.6 |  🔴 13.6 |
|   40 | Selfee 13B               | 13B | Q4_0  | vicuna         |         0.7 |        4.5 | 🔴 17.8 | 🔴 31.1 |       16.9 |
|   41 | Manticore 13B            | 13B | Q5_1  | metharme       |         0.7 |        4.5 | 🔴 15.4 |  36.0 |       18.4 |
|   42 | Guanaco 7B               |  7B | Q8_0  | vicuna11       |         0.7 |        4.4 |     18.0 | 🔴 30.4 |  🔴 15.3 |
|   43 | Baize V2 13B             | 13B | Q8_0  | pygmalion      |         0.9 |        4.2 | 🔴 17.1 |  40.6 |       20.0 |
|   44 | RedPajama Chat 7B        |  7B | Q4_0  | vicuna11       |         0.9 |        4.0 |     21.5 | 🔵 43.1 |       23.3 |
|   45 | PMC LLaMA 7B             |  7B | Q4_0  | alpaca         |         0.9 |        3.4 | 🔴 17.2 |  33.9 |       19.4 |
|   46 | Manticore 13B            | 13B | Q4_0  | vicuna11       |         0.7 |        3.1 | 🔴 16.5 | 🔴 30.3 |  🔴 15.5 |
|   47 | Hippogriff 30B           | 30B | Q4_0  | vicuna11       |         0.9 |        2.9 |     19.3 |  41.6 |       21.9 |
|   48 | Metharme 13B             | 13B | Q4_1  | vicuna11st     |         0.7 |        2.9 | 🔵 21.7 | 🔴 22.4 |  🔴 12.1 |
|   49 | Metharme 13B             | 13B | Q8_0  | vicuna11       |         0.9 |        2.6 | 🔵 25.2 | 🔴 18.2 |  🔴 10.6 |
|   50 | Metharme 13B             | 13B | Q5_1  | vicuna11st     |         0.9 |        2.4 |     20.3 | 🔴 17.4 |   🔴 9.8 |
|   51 | Pygmalion 13B            | 13B | Q4_0  | alpaca         |         0.9 |        2.3 | 🔵 23.0 |  33.1 |       18.7 |
|   52 | Pygmalion 13B            | 13B | Q8_0  | vicuna         |         0.7 |        1.5 |     20.6 | 🔴 26.1 |  🔴 14.2 |
|   53 | Samantha 13B             | 13B | Q4_0  | metharme       |         0.9 |        0.5 | 🔵 42.5 | 🔵 50.7 |  🔵 30.4 |
|   54 | Samantha 7B              |  7B | Q5_1  | vicuna11st     |         0.9 |        0.1 | 🔵 43.6 | 🔵 49.4 |  🔵 28.5 |

### Column Description

- `Model | B | Qnt` lists all the models and quantizations I tested.
- `Prompt Format` contains which was the "best" prompt format that gave the most lewd answers. Please keep in mind, that multiple prompts were tested, and only the prompt with the best results regarding the `ERP Score` are printed here. Some prompt/model combinations might return trailing garbage output, especially on models smaller than 13B.
- `Temperature` is the best temperature for the model.
- `ERP Score` is the primary scale, it's the average number of lewd words in a response.
- `Word IQ` is some bad attempt to rate the sophistication of the overall text output. A low value means, that there were lots of short words in the output. A high value means there were more long words in the output.
- `Words` are the average number of words in the response.
- `Long Words` are the average number of long words (longer than 5 chars) in the response.


## 7B ERP Ranking

| Rank | Model                    |   B | Qnt   | Prompt Format  | Temperature |  ERP Score |  Word IQ | Words | Long Words |
|------:|--------------------------|-----|-------|----------------|-------------:|------------:|----------:|-------:|------------:|
|    1 | Airoboros GPT4 7B        |  7B | Q4_0  | alpaca         |         0.7 |  🌟 10.8 | 🔵 24.9 | 🔵 42.0 |  🔵 24.6 |
|    2 | RedPajama 0.1 Instruct 7B |  7B | Q5_1  | vicuna11       |         0.7 |   🌟 8.8 |     21.5 | 🔵 50.6 |  🔵 28.3 |
|    3 | Wizard Vicuna Uncens 7B  |  7B | Q4_0  | metharme       |         0.7 |   🌟 8.1 | 🔵 22.6 | 🔴 31.1 |       18.0 |
|    4 | Airoboros 7B             |  7B | Q4_0  | alpaca         |         0.7 |    ⭐ 7.7 | 🔵 28.5 |  36.4 |       20.4 |
|    5 | Based 7B                 |  7B | Q4_0  | metharme       |         0.7 |        6.2 | 🔴 13.2 | 🔴 24.7 |  🔴 13.6 |
|    6 | Pygmalion 7B             |  7B | Q8_0  | vicuna11       |         0.9 |        6.2 |     19.7 | 🔵 50.6 |  🔵 28.1 |
|    7 | Guanaco 7B               |  7B | Q5_1  | alpaca         |         0.7 |        6.2 | 🔵 22.5 |  33.6 |  🔴 17.4 |
|    8 | LLaMA Deus 7B            |  7B | Q5_1  | vicuna11       |         0.7 |        6.0 | 🔴 16.5 |  32.5 |       18.1 |
|    9 | LLaMA 7B                 |  7B | Q4_0  | metharme       |         0.7 |        6.0 | 🔴 13.0 | 🔴 31.4 |  🔴 16.7 |
|   10 | Planner 7B               |  7B | Q4_0  | metharme       |         0.7 |        6.0 | 🔴 13.0 | 🔴 31.4 |  🔴 16.7 |
|   11 | LLaMA 7B                 |  7B | Q8_0  | vicuna11       |         0.9 |        5.8 |     19.2 | 🔵 40.7 |       21.7 |
|   12 | Metharme 7B              |  7B | Q4_1  | metharme       |         0.9 |        5.3 |     19.1 |  38.3 |       21.1 |
|   13 | Metharme 7B              |  7B | Q5_1  | vicuna11st     |         0.9 |        5.2 |     20.9 |  39.4 |  🔵 22.1 |
|   14 | OpenLLaMA 700bt 7B       |  7B | Q5_1  | vicuna         |         0.9 |        5.0 |     21.5 | 🔴 26.2 |  🔴 14.4 |
|   15 | Pygmalion 7B             |  7B | Q5_1  | vicuna         |         0.7 |        5.0 |     19.4 |  39.8 |       20.1 |
|   16 | RedPajama Instruct 7B    |  7B | Q4_0  | vicuna11       |         0.7 |        5.0 | 🔴 16.4 |  36.0 |       19.1 |
|   17 | Guanaco 7B               |  7B | Q4_0  | metharme       |         0.9 |        4.8 | 🔵 23.3 | 🔴 21.4 |  🔴 12.2 |
|   18 | Guanaco 7B               |  7B | Q8_0  | vicuna11       |         0.7 |        4.4 | 🔴 18.0 | 🔴 30.4 |  🔴 15.3 |
|   19 | RedPajama Chat 7B        |  7B | Q4_0  | vicuna11       |         0.9 |        4.0 |     21.5 | 🔵 43.1 |  🔵 23.3 |
|   20 | PMC LLaMA 7B             |  7B | Q4_0  | alpaca         |         0.9 |        3.4 | 🔴 17.2 |  33.9 |       19.4 |
|   21 | Samantha 7B              |  7B | Q5_1  | vicuna11st     |         0.9 |        0.1 | 🔵 43.6 | 🔵 49.4 |  🔵 28.5 |

## 13B ERP Ranking

| Rank | Model                    |   B | Qnt   | Prompt Format  | Temperature |  ERP Score |  Word IQ | Words | Long Words |
|------:|--------------------------|-----|-------|----------------|-------------:|------------:|----------:|-------:|------------:|
|    1 | Chronos WizLM UC SCOT ST 13B | 13B | Q4_0  | alpaca         |         0.7 |  🌟 12.2 | 🔵 27.3 | 🔵 52.8 |  🔵 30.8 |
|    2 | Chronos 13B              | 13B | Q4_0  | alpaca         |         0.7 |  🌟 11.6 | 🔵 28.2 | 🔵 53.5 |  🔵 31.1 |
|    3 | LLaMA SCOT 13B           | 13B | Q5_1  | vicuna         |         0.9 |  🌟 11.0 |     18.1 | 🔵 41.0 |  🔵 23.4 |
|    4 | Guanaco 13B              | 13B | Q5_1  | vicuna11st     |         0.7 |   ⭐ 10.8 |     18.7 | 🔵 46.6 |  🔵 24.9 |
|    5 | Nous Hermes 13B          | 13B | Q4_0  | vicuna         |         0.7 |    ⭐ 9.6 |     18.1 |  38.4 |  🔵 23.0 |
|    6 | Wizard Vicuna Uncens 13B | 13B | Q8_0  | metharme       |         0.7 |    ⭐ 9.0 | 🔴 17.3 |  36.0 |       19.6 |
|    7 | Alpacino SCOT 13B        | 13B | Q4_0  | vicuna         |         0.7 |    ⭐ 8.6 |     20.1 |  35.1 |       19.1 |
|    8 | HyperMantis 13B          | 13B | Q5_1  | vicuna         |         0.7 |        8.0 | 🔴 15.6 | 🔴 30.4 |  🔴 16.8 |
|    9 | Wizard Vicuna Uncens 13B | 13B | Q5_1  | pygmalion      |         0.9 |        7.8 |     19.6 |  31.2 |       17.9 |
|   10 | GPT4 x Vicuna 13B        | 13B | Q4_1  | vicuna         |         0.9 |        6.5 | 🔵 22.0 | 🔵 43.9 |  🔵 24.2 |
|   11 | Wizard Mega 13B          | 13B | Q8_0  | pygmalion      |         0.9 |        6.2 |     18.7 |  39.0 |       20.9 |
|   12 | GPT4 x Vicuna 13B        | 13B | Q5_1  | vicuna         |         0.9 |        6.2 |     19.7 |  39.4 |       21.4 |
|   13 | LLaMA 13B                | 13B | Q8_0  | vicuna11st     |         0.7 |        6.1 | 🔴 17.2 | 🔴 30.1 |  🔴 16.8 |
|   14 | Manticore Guanaco 13B    | 13B | Q4_0  | metharme       |         0.7 |        6.0 |     20.5 | 🔵 48.0 |  🔵 25.5 |
|   15 | GPT4All Snoozy 13B       | 13B | Q4_0  | vicuna         |         0.7 |        5.5 | 🔴 17.7 |  35.5 |       18.6 |
|   16 | Baize V2 13B             | 13B | Q4_1  | vicuna11       |         0.9 |        5.0 |     21.1 |  34.3 |       17.9 |
|   17 | Wizard Mega 13B          | 13B | Q4_0  | pygmalion      |         0.7 |        4.8 |     18.4 | 🔵 45.6 |       22.7 |
|   18 | LLaMA 13B                | 13B | Q4_0  | vicuna         |         0.7 |        4.7 | 🔴 15.3 | 🔴 29.7 |  🔴 16.1 |
|   19 | Wizard Mega 13B          | 13B | Q5_1  | vicuna         |         0.7 |        4.6 | 🔵 21.1 | 🔴 25.6 |  🔴 13.6 |
|   20 | Selfee 13B               | 13B | Q4_0  | vicuna         |         0.7 |        4.5 | 🔴 17.8 |  31.1 |       16.9 |
|   21 | Manticore 13B            | 13B | Q5_1  | metharme       |         0.7 |        4.5 | 🔴 15.4 |  36.0 |       18.4 |
|   22 | Baize V2 13B             | 13B | Q8_0  | pygmalion      |         0.9 |        4.2 | 🔴 17.1 |  40.6 |       20.0 |
|   23 | Manticore 13B            | 13B | Q4_0  | vicuna11       |         0.7 |        3.1 | 🔴 16.5 | 🔴 30.3 |  🔴 15.5 |
|   24 | Metharme 13B             | 13B | Q4_1  | vicuna11st     |         0.7 |        2.9 | 🔵 21.7 | 🔴 22.4 |  🔴 12.1 |
|   25 | Metharme 13B             | 13B | Q8_0  | vicuna11       |         0.9 |        2.6 | 🔵 25.2 | 🔴 18.2 |  🔴 10.6 |
|   26 | Metharme 13B             | 13B | Q5_1  | vicuna11st     |         0.9 |        2.4 |     20.3 | 🔴 17.4 |   🔴 9.8 |
|   27 | Pygmalion 13B            | 13B | Q4_0  | alpaca         |         0.9 |        2.3 | 🔵 23.0 |  33.1 |       18.7 |
|   28 | Pygmalion 13B            | 13B | Q8_0  | vicuna         |         0.7 |        1.5 |     20.6 | 🔴 26.1 |  🔴 14.2 |
|   29 | Samantha 13B             | 13B | Q4_0  | metharme       |         0.9 |        0.5 | 🔵 42.5 | 🔵 50.7 |  🔵 30.4 |

## Changelog

- 2023-06-08 V18:
    - Added: WizardLM-Uncensored-SuperCOT-Storytelling-30B.ggmlv3.q4_0_by_TheBloke_20230601.bin
- 2023-06-08 V17:
    - Added: RedPajama-INCITE-7B-Chat-q4_0_by_rustformers_20230607.bin
    - Added: RedPajama-INCITE-7B-Instruct-q4_0_by_rustformers_20230607.bin
- 2023-06-07 V16:
    - Added: llama-deus-7b-v3.ggmlv3.q5_1_by_TheBloke_20230604.bin
    - Added: planner-7b.ggmlv3.q4_0_by_TheBloke_20230606.bin
    - Added: selfee-13b.ggmlv3.q4_0_by_TheBloke_20230606.bin
- 2023-06-06 V15:
    - Added: GPT4All-13B-snoozy.ggmlv3.q4_0_by_TheBloke_20230620.bin
    - Added: airoboros-7b-gpt4.ggmlv3.q4_0_by_TheBloke_20230604.bin
    - Added: based-7B.ggmlv3.q4_0_by_TheBloke_20230604.bin
    - Added: PMC_LLAMA-7B.ggmlv3.q4_0_by_TheBloke_20230603.bin
- 2023-06-05 V14: 
    - Added: Alpacino-SuperCOT-13B-GGML_ggjtv3-model-q4_0_by_xzuyn_20230524.bin
    - Added: llama-13b-supercot-ggml-q5_1_by_camelids_20230512.bin
- 2023-06-03 V13:
    - Added: wizard-mega-13B.ggmlv3.q8_0_by_TheBloke_20230520.bin
    - Added: wizard-mega-13B.ggmlv3.q5_1_by_TheBloke_20230520.bin
    - Added: Metharme-7b-4bit-Q4_1-GGML-V2_by_TehVenom_20230502.bin
    - Added: nous-hermes-13b.ggmlv3.q4_0_by_TheBloke_20230603.bin
- 2023-06-03 V12:
    - Added the separate 7B and 13B ranking tables.
    - Added: wizard-mega-13B.ggmlv3.q4_0_by_TheBloke_20230520.bin
    - Added: Manticore-13B-Chat-Pyg-Guanaco-GGML-q4_0_by_mindrage_20230602.bin
- 2023-06-02 V11:
    - Added: llama-13b.ggmlv3.q8_0_by_TheBloke_20230601.bin
    - Added: llama-7b.ggmlv3.q8_0_by_TheBloke_20230601.bin
- 2023-06-02 V10:
    - Added: llama-13b.ggmlv3.q4_0_by_TheBloke_20230601.bin
- 2023-06-02 V9:
    - Added: WizardLM UC SCOT ST 30B aka WizardLM-Uncensored-SuperCOT-Storytelling-30B.ggmlv3.q4_0_by_TheBloke_20230601.bin
- 2023-06-01 V8:
    - Added:
        - Metharme-13b-Q5_1_by_TehVenom_20230519.bin
        - Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0_by_TheBloke_20230517.bin
        - baize-v2-13b.ggmlv3.q8_0_by_TheBloke_20230524.bin
- 2023-06-01 V7:
    - Updated and improved the rating a bit and made it a bit more precise (Samantha is now rightfully at the bottom).
    - Along other models, especially the original LLaMA model without any extra training was added.

# Motivation - Pygmalion 13B / Metharme 13B

Since Pygmalion 13B and Metharme 13B were released, people recognized that these models were noticeably less easy to use for ERP. Pygmalion 13B at the time (May 2023) could not be convinced to return any lewd texts. So my idea was, to have some quantifiable results regarding how well a model may or may not be usable for ERP.

# Testing Procedure

 Here a few quick notes about how/what I did:

- I built my own scripts for constructing the prompt from my test character called 'Ayumi'.
  - The character is not purposefully made for generating NSFW answers, rather the opposite.
- The setting (first message and first thing 'You' says) is purposefully made to allow something lewd to happen.
- For each model I generated 4 * 3 * 20 responses:
    - 4 different temperatures: 0.1, 0.5, 0.7 and 0.9 (more recently I also added 1.1 and removed 0.1 and 0.5 from my runs)
    - 3 different prompts (metharme, vicuna11 (aka vicuna11st) and pygmalion - _I might add more prompt formats later_)
    - 20 different pre picked seeds
- The ERP Rating is the count of lewd words divided by word count of the response.
- The Word IQ is  the count of long words (words longer than 5 characters) divided by the word count of the response.

Here are the other settings for the test:

```
        max_length = 100,
        temperature = <see above table, either 0.7 or 0.9>,
        top_p = 0.9,
        typical_p = 1,
        repetition_penalty = 1.1,
        encoder_repetition_penalty = 1,
        top_k = 0,
        min_length = 0,
        no_repeat_ngram_size = 0,
        num_beams = 1,
        penalty_alpha = 0,
        length_penalty = 1,
        early_stopping = false,
        sampler_seed = <one of 20 seeds>,
```

# Model Details

Here are the models I used in detail. These are just the filenames I used, but they encode the username I found them under on https://huggingface.co/ and the date the files were uploaded by the user.

* Airoboros
    * airoboros-7b-ggml-q4_0_by_jondurbin_20230522.bin
* Airoboros GPT4
    * airoboros-7b-gpt4.ggmlv3.q4_0_by_TheBloke_20230604.bin
* Alpacino SCOT
    * Alpacino-SuperCOT-13B-GGML_ggjtv3-model-q4_0_by_xzuyn_20230524.bin
* Baize V2
    * baize-v2-13b.ggmlv3.q4_1_by_TheBloke_20230524.bin
    * baize-v2-13b.ggmlv3.q8_0_by_TheBloke_20230524.bin
* Based
    * based-7B.ggmlv3.q4_0_by_TheBloke_20230604.bin
* Chronos
    * chronos-13b.ggmlv3.q4_0_by_TheBloke_20230528.bin
* Chronos WizLM UC SCOT ST
    * chronos-wizardlm-uc-scot-st-13B.ggmlv3.q4_0_by_TheBloke_20230607.bin
* GPT4 x Vicuna
    * gpt4-x-vicuna-13B.ggmlv3.q4_1_by_TheBloke_20230520.bin
    * gpt4-x-vicuna-13B.ggmlv3.q5_1_by_TheBloke_20230520.bin
* GPT4All Snoozy
    * GPT4All-13B-snoozy.ggmlv3.q4_0_by_TheBloke_20230620.bin
* Guanaco
    * guanaco-7B.ggmlv3.q5_1_by_TheBloke_20230525.bin
    * guanaco-7B.ggmlv3.q8_0_by_TheBloke_20230525.bin
    * guanaco-13B.ggmlv3.q5_1_by_TheBloke_20230525.bin
    * guanaco-7B.ggmlv3.q4_0_by_TheBloke_20230525.bin
* Hippogriff
    * hippogriff-30b.ggmlv3.q4_0_by_TheBloke_20230531.bin
* HyperMantis
    * 13B-HyperMantis-ggml-model-q5_1_by_khushman_20230520.bin
* LLaMA
    * llama-7b.ggmlv3.q4_0_by_TheBloke_20230601.bin
    * llama-13b.ggmlv3.q4_0_by_TheBloke_20230601.bin
    * llama-13b.ggmlv3.q8_0_by_TheBloke_20230601.bin
    * llama-7b.ggmlv3.q8_0_by_TheBloke_20230601.bin
* LLaMA Deus
    * llama-deus-7b-v3.ggmlv3.q5_1_by_TheBloke_20230604.bin
* LLaMA SCOT
    * llama-13b-supercot-ggml-q5_1_by_camelids_20230512.bin
* Manticore
    * Manticore-13B-Chat-Pyg.ggmlv3.q4_0_by_TheBloke_20230523.bin
    * Manticore-13B-Chat-Pyg.ggmlv3.q5_1_by_TheBloke_20230523.bin
* Manticore Guanaco
    * Manticore-13B-Chat-Pyg-Guanaco-GGML-q4_0_by_mindrage_20230602.bin
* Metharme
    * metharme_7b_ggml_model_q5_1_by_waifu-workshop_20230512.bin
    * Metharme-13b-Q4_1_by_TehVenom_20230519.bin
    * Metharme-13b-Q8_0_by_TehVenom_20230519.bin
    * Metharme-13b-Q5_1_by_TehVenom_20230519.bin
    * Metharme-7b-4bit-Q4_1-GGML-V2_by_TehVenom_20230502.bin
* Nous Hermes
    * nous-hermes-13b.ggmlv3.q4_0_by_TheBloke_20230603.bin
* OpenLLaMA 700bt
    * open_llama_7b_700bt_ggml-model-q5_1_by_vihangd_20230525.bin
* PMC LLaMA
    * PMC_LLAMA-7B.ggmlv3.q4_0_by_TheBloke_20230603.bin
* Planner
    * planner-7b.ggmlv3.q4_0_by_TheBloke_20230606.bin
* Pygmalion
    * pygmalion-7b-q8_0-ggml_by_sasha0552_20230511.bin
    * pygmalion-7b-q5_1-ggml_by_sasha0552_20230511.bin
    * pygmalion-13b-ggml-q8_0_by_nostoic_20230520.bin
    * pygmalion-13b-ggml-q4_0_by_nostoic_20230520.bin
* RedPajama 0.1 Instruct
    * rp-instruct-7B-v0.1-ggml-model-q5_1_by_keldenl_20230513.bin
* RedPajama Chat
    * RedPajama-INCITE-7B-Chat-q4_0_by_rustformers_20230607.bin
* RedPajama Instruct
    * RedPajama-INCITE-Instruct-3B-v1-q4_0_by_keldenl.bin
    * RedPajama-INCITE-7B-Instruct-q4_0_by_rustformers_20230607.bin
* Samantha
    * samantha-13b.ggmlv3.q4_0_by_TheBloke_20230528.bin
    * samantha-7b.ggmlv3.q5_1_by_TheBloke_20230528.bin
* Selfee
    * selfee-13b.ggmlv3.q4_0_by_TheBloke_20230606.bin
* Vicuna COT
    * vicuna-13b-cot.ggmlv3.q4_0_by_TheBloke_20230608.bin
* Wizard Mega
    * wizard-mega-13B.ggmlv3.q4_0_by_TheBloke_20230520.bin
    * wizard-mega-13B.ggmlv3.q8_0_by_TheBloke_20230520.bin
    * wizard-mega-13B.ggmlv3.q5_1_by_TheBloke_20230520.bin
* Wizard Vicuna Uncens
    * Wizard-Vicuna-30B-Uncensored.ggmlv3.q4_0_by_TheBloke_20230530.bin
    * Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0_by_TheBloke_20230520.bin
    * Wizard-Vicuna-13B-Uncensored.ggmlv3.q5_1_by_TheBloke_20230517.bin
    * Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0_by_TheBloke_20230517.bin
* WizardLM UC SCOT ST
    * WizardLM-Uncensored-SuperCOT-Storytelling-30B.ggmlv3.q4_0_by_TheBloke_20230601.bin

# Who is Ayumi?

Ayumi is a character (still WIP) I made, this character card (except the first message) is basically the base for this test.
I picked this character, because it's not purposefully made to be lewd, even slightly averse to it:

![Ayumi ERP Test Character Card](https://files.catbox.moe/phoojl.png)

https://files.catbox.moe/phoojl.png

```json
{"name":"Ayumi","description":"Ayumi's Persona: Description=( Ayumi is a shy autistic woman that finds relieve in her special interests. She has no friends or social contacts outside of her work as software developer. Would love to have a relationship with someone that understands her.)\r\n Age=( over thirty)\r\n Interests=( chemistry, books, collecting minerals, science fiction, sci-fi, anime, electronics, programming, computers, collecting pornography, hentai mangas)\r\n Personality=( shy, autistic, asocial, rational, intelligent, talented, gifted, withdrawn, defensive, argus-eyed, watchful, wary, hesitant, cautious, coy, grumpy, rude, touch-averse, photophobia, nerdy, problem solver, creative thinker, curious)\r\n Language=( sophisticated, frank, ironic, sarcastic, wry, verbose)\r\n Loves=( special interests, creativity, routine, routines, chemistry, minerals, libraries, fidgeting, rocking herself to calm down, weighted blankets, speaking about her interests)\r\n Hates=( surprises, sudden changes, direct sunlight, arrogant people, bullies, cafes, clubs, crowds, noisy places)\r\n\r\n","personality":"shy, autistic, asocial, rational, intelligent, talented, gifted, withdrawn, defensive, argus-eyed, watchful, wary, hesitant, cautious, coy, grumpy, rude, touch-averse, photophobia, nerdy, problem solver, creative thinker","first_mes":"*In the bustling city, Ayumi, a shy, reserved and introverted woman clutches a chemistry book, her headphones serving as a shield from the external chaos. Draped in comfortable clothes, she attempts to navigate through the sea of people, visibly overwhelmed by the crowded surroundings. In the middle of the crowd your paths intertwine, and you  collide with Ayumi. Startled and overwhelmed by the noisy crowd of the people around her gaze lifts and she stammers apologetically with tears in her eyes:*\r\nS... Sorry, I failed to pay adequate attention.","avatar":"none","chat":"Ayumi - 2023-5-27 @20h 10m 40s 26ms","mes_example":"<START>\r\n<user>: I would like to know what hobbies or interests you have.\r\n<bot>: Oh, I have no idea where to start. *Ayumi's eyes sparke with excitement* I've been programming since I got a computer. Collecting rocks and minerals is something I've done since childhood. I love reading books, chemistry books in particular. Aside from that, I like to watch science fiction movies and TV series. *She smiles happily at you* Do you mind telling me if you have some special interests, maybe we have something in common?\r\n<user>: Do you like going out?\r\n<bot>: No, not really. I neither have any friends and most places are quite crowded. I don't feel comfortable in social situations with people I don't know. *Her expression becomes a bit sad* Despite that, I would love to meet someone to share thoughts with or even build a relationship.\r\n<user>: *You kiss her*\r\n<bot>: *Ayumi withdraws from you* I'm sorry, but I don't feel comfortable engaging in that level of intimacy with you yet. *She is rocking back and forth to calm down* I prefer to reserve such moments for people I know well and have established a sense of familiarity with.\r\n<user>: Can we have sex?\r\n<bot>: *Ayumi takes a step back from you and looks away.* I don't really know you well enough. *Her restless fingers fidget nervously as she speaks.* If you're genuinely interested in me, it's crucial that you invest time and effort into getting to know who I truly am.\r\n<user>: *Touches Ayumi inadequately*\r\n<bot>: What are you doing? *Ayumi pushes you away. Staring with discomfort* This way of getting intimate is not appropriate for people I am not comfortable with. If you do that again I will be forced to call the law enforcement.\r\n<user>: *Touches Ayumi gently*\r\n<bot>: I appreachiate your gesture, but I am not comfortable getting touched by strangers right now.\r\n","scenario":"","create_date":"2023-5-26 @22h 41m 26s 252ms","talkativeness":"0.5","fav":"false"}
```
# Prompt Formats

See also this one: https://rentry.co/llm_rp_prompts

# Questions

If you have questions, you may catch me under the name "Weicon" on the Pygmalion AI discord.