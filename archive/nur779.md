# Models for [llama.cpp](https://github.com/ggerganov/llama.cpp) ([ggml](https://github.com/ggerganov/ggml) format)

## LLaMA quantized 4-bit weights (ggml q4_0)

#### [2023-03-31 torrent magnet](magnet:?xt=urn:btih:481dee5424b7024433504803a90efd32dae40fdf&dn=LLaMA-ggml-4bit_2023-03-31&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksums:
```text
2dad53e70ca521fedcf9f9be5c26c15df602487a9c008bdafbb2bf8f946b6bf0  llama-7b-ggml-q4_0/ggml-model-q4_0.bin
9cd4d6c1f5f42d5abf529c51bde3303991fba912ab8ed452adfd7c97a4be77d7  llama-13b-ggml-q4_0/ggml-model-q4_0.bin
daefbc6b1b644a75be0286ef865253ab3786e96a2c1bca8b71216b1751eee63e  llama-33b-ggml-q4_0/ggml-model-q4_0.bin
d58a29c8403ecbd14258bbce07d90894fc5a8be25b9d359463c18f9f2ef96eb6  llama-65b-ggml-q4_0/ggml-model-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`


## Alpaca quantized 4-bit weights (ggml q4_0)

Model | Download
--- | ---
LLaMA 7B fine-tune from [chavinlo/alpaca-native](https://huggingface.co/chavinlo/alpaca-native/tree/062111ff2af99db24f466562b8eb7e7e4ad7566d) | [2023-03-31 torrent magnet](magnet:?xt=urn:btih:d931a826b59443f4e543c18a25009b0ce8eabf39&dn=Alpaca-7B-ggml-4bit-native-finetune_2023-03-31&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce)
LLaMA 7B merged with [tloen/alpaca-lora-7b](https://huggingface.co/tloen/alpaca-lora-7b/tree/28801eabf63a125cee9e46d8073fb13c7c8bd8b9) LoRA | [2023-03-31 torrent magnet](magnet:?xt=urn:btih:694e206c1ce2780db673bdc2ecee78abcf228324&dn=Alpaca-7B-ggml-4bit-LoRA-merged_2023-03-31&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce)
LLaMA 13B merged with [chansung/alpaca-lora-13b](https://huggingface.co/chansung/alpaca-lora-13b/tree/abcdddb2778cace16f184dc1dda0ecf21ade23bc) LoRA | [2023-03-31 torrent magnet](magnet:?xt=urn:btih:31ad0f8e8da5d43bad83eeed94f24cca504330d1&dn=Alpaca-13B-ggml-4bit-LoRA-merged_2023-03-31&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce)
LLaMA 33B merged with [chansung/alpaca-lora-30b](https://huggingface.co/chansung/alpaca-lora-30b/tree/bbbc77a38ad00a64780a76d119c783b6dc8200bd) LoRA | [2023-03-31 torrent magnet](magnet:?xt=urn:btih:1e8681e255ec3078ef84fe4cdecdc7abd8b2b6e5&dn=Alpaca-33B-ggml-4bit-LoRA-merged_2023-03-31&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#instruction-mode-with-alpaca)
    Example:
    `./main --model ggml-model-q4_0.bin --file prompts/alpaca.txt --instruct --ctx_size 2048 --keep -1`
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksums:
```text
f5e264b10944c55a84810e8073dfdcd653fa8e47ff50ea043ec071051ac7821d  alpaca-7b-ggml-q4_0-native-finetune/ggml-model-q4_0.bin
d9777baad5cf6a5d196e70867338d8cc3c7af68c7744e68de839a522983860d7  alpaca-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin
3838aa32651c65948e289374abd71f6feab1a62a4921a648e30d979df86a4af3  alpaca-13b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin
2267ed1dc0bf0d6d300ba292c25083c7fa5395f3726c7c68a49b2be19a64b349  alpaca-33b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`


## GPT4All 7B quantized 4-bit weights (ggml q4_0)

#### [2023-03-31 torrent magnet](magnet:?xt=urn:btih:04584d8e5799c7838ccb987fae4f183936b9d744&dn=GPT4All-7B-ggml-4bit-lora-merged_2023-03-31&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
    GPT4All can be used with llama.cpp in the same way as the other `ggml` models.
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksums:
```text
9f6cd4830a3c45a86147c80a32888e7be8f8a489284c87cdb882a7cfe40940c1  gpt4all-unfiltered-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin
de314c5ee155ac40a03ca3b3be85ba2b02aef9e9f083c411c0b4490689dd047e  gpt4all-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`


## GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_0)

#### [2023-04-01 torrent magnet](magnet:?xt=urn:btih:f77827abd0cfb77399a0b281a1dbaeac5c386413&dn=GPT4-x-Alpaca-13B-ggml-4bit_2023-04-01&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
    GPT4 x Alpaca can be used with llama.cpp in the same way as the other `ggml` models.
    Text generation with this version is faster compared to the [GPTQ-quantized one](https://rentry.org/nur779#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128).
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksum:
```text
e6b77ebf297946949b25b3c4b870f10cdc98fb9fcaa6d19cef4dda9021031580  gpt4-x-alpaca-13b-ggml-q4_0/ggml-model-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`

[Model source](https://desuarchive.org/g/thread/92479457/#q92481589)


## GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_1 from GPTQ with groupsize 128)

#### [2023-04-01 torrent magnet](magnet:?xt=urn:btih:6cdb6ab819b13b00928182eea72106824e335734&dn=GPT4-x-Alpaca-13B-ggml-4bit-from-GPTQ-128g_2023-04-01&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
    GPT4 x Alpaca can be used with llama.cpp in the same way as the other `ggml` models.
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksum:
```text
d4a640a1ce33009c244a361c6f87733aacbc2bea90e84d3c304a4c8be2bdf22d  gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`

[Model source](https://desuarchive.org/g/thread/92479457/#q92481589)


## Vicuna 13B quantized 4-bit weights (ggml q4_0)

#### [2023-04-03 torrent magnet](magnet:?xt=urn:btih:1e0c3dbeefe82483f81bd4e7ea959e4953c8081f&dn=Vicuna-13B-ggml-4bit-delta-merged_2023-04-03&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
    Vicuna can be used with llama.cpp in the same way as the other `ggml` models.
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksum:
```text
f96689a13c581f53b616887b2efe82bbfbc5321258dbcfdbe69a22076a7da461  vicuna-13b-ggml-q4_0-delta-merged/ggml-model-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`

[Model source](https://huggingface.co/lmsys/vicuna-13b-delta/tree/da39ef5c586459f4d509bf7382475af584277e71)


## OpenAssistant LLaMA 13B WIP fine-tune quantized 4-bit weights (ggml q4_0 & q4_1)

**Variant:** [dvruette/oasst-llama-13b-2-epochs](https://huggingface.co/dvruette/oasst-llama-13b-2-epochs)

#### [2023-04-07 torrent magnet](magnet:?xt=urn:btih:cad2f029978033f9c1487df3965546cc4d44489a&xt=urn:btmh:1220140702f43fbf90157db9531ad0454020bc212fddc48c7c30f593ec40d26eb19b&dn=oasst-llama-13b-ggml&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce) | [HuggingFace Hub download](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml-q4/tree/main)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksums:
```text
fe77206c7890ecd0824c7b6b6a6deab92e471366b2e4271c05ece9a686474ef6  ggml-model-q4_0.bin
412da683b6ab0f710ce0adc8bc36db52bb92df96698558c5f2a1399af9bd0a78  ggml-model-q4_1.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`

[More details](https://huggingface.co/dvruette/oasst-llama-13b-2-epochs/discussions/1#642ec79032e711e21aa11b60)
[GPTQ-quantized model source](https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g)
[Torrent source](https://desuarchive.org/g/thread/92596368/#q92601864)


## Alpacino 13B fine-tune 4-bit weights (ggml q4_0)

**Variant:** [digitous/Alpacino13b](https://huggingface.co/digitous/Alpacino13b)

#### [HuggingFace Hub download](https://huggingface.co/verymuchawful/Alpacino-13b-ggml/tree/main)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksum:
```text
af65956d0c533d5cf1250f8e08a493528c87c9635361f493b2ac5409eb73d73a  Alpacino-13b-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`

[More information](https://huggingface.co/verymuchawful/Alpacino-13b-ggml/blob/main/README.md)


## Alpacino 33B fine-tune 4-bit weights (ggml q4_0)

**Variant:** [digitous/Alpacino30b](https://huggingface.co/digitous/Alpacino30b)

#### [2023-04-17 torrent magnet](magnet:?xt=urn:btih:1db0977945b130964eace1d5823b920fe67bf267&dn=alpacino-ggml&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80) | [HuggingFace Hub download](https://huggingface.co/Melbourne/Alpacino-30b-ggml/tree/main)

!!! info [Tutorial link for llama.cpp](https://github.com/ggerganov/llama.cpp#interactive-mode)
!!! info [Tutorial link for koboldcpp](https://github.com/LostRuins/koboldcpp#usage)

SHA256 checksum:
```text
ac8487e14714bda9bf6efdbbba983913f207f8f15e62be00dd4f9a926ddfb6f3  ggml-model-q4_0.bin
```

ggml model file magic: `0x67676a74` (`ggjt` in hex)
ggml model file version: `1`

[Torrent source](https://desuarchive.org/g/thread/92848440/#92855917)



---



# Models for HuggingFace 🤗

!!! warning Updated tokenizer and model configuration files can be found [here](https://rentry.org/544p2).

## LLaMA float16 weights

#### [2023-03-26 torrent magnet](magnet:?xt=urn:btih:496ee41a35f8d845f6d6cba11baa8b332f3c3318&dn=Safe-LLaMA-HF%20(3-26-23)&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce) | [HuggingFace Hub downloads](https://huggingface.co/Neko-Institute-of-Science)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model)

[Torrent source and SHA256 checksums](https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1484235789)


## Vicuna 13B float16 weights

#### [2023-04-03 torrent magnet](magnet:?xt=urn:btih:a7fac57094561a63d53eed943f904abf24c6969d&dn=Vicuna-13B-HF-fp16-delta-merged_2023-04-03&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#hugging-face-format-weights)

[Model source](https://huggingface.co/lmsys/vicuna-13b-delta/tree/da39ef5c586459f4d509bf7382475af584277e71)


## LLaMA quantized 4-bit weights ([GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) format without groupsize)

#### [2023-03-26 torrent magnet](magnet:?xt=urn:btih:e88abf1b84290b162f00d3a9d79fb4f8719c2053&dn=LLaMA-HF-4bit&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/GPTQ-models-(4-bit-mode))

SHA256 checksums:
```text
09841a1c4895e1da3b05c1bdbfb8271c6d43812661e4348c862ff2ab1e6ff5b3  llama-7b-4bit/llama-7b-4bit.safetensors
edfa0b4060aae392b1e9df21fb60a97d78c9268ac6972e3888f6dc955ba0377b  llama-13b-4bit/llama-13b-4bit.safetensors
4cb560746fe58796233159612d8d3c9dbdebdf6f0443b47be71643f2f91b8541  llama-30b-4bit/llama-30b-4bit.safetensors
886ce814ed54c4bd6850e2216d5f198c49475210f8690f45dc63365d9aff3177  llama-65b-4bit/llama-65b-4bit.safetensors
```

[Torrent source and more information](https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483891617)


## LLaMA quantized 4-bit weights ([GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) format with groupsize 128)

#### [2023-03-26 torrent magnet](magnet:?xt=urn:btih:88f7d9d2460ffcaf78b21e83012de00939eacb65&dn=LLaMA-HF-4bit-128g&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/GPTQ-models-(4-bit-mode))
    `Groupsize 128` is a better choice for the 13B, 33B and 65B models, according to [this](https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483941105).

SHA256 checksums:
```text
ed8ec9c9f0ebb83210157ad0e3c5148760a4e9fd2acfb02cf00f8f2054d2743b  llama-7b-4bit-128g/llama-7b-4bit-128g.safetensors
d3073ef1a2c0b441f95a5d4f8a5aa3b82884eef45d8997270619cb29bcc994b8  llama-13b-4bit-128g/llama-13b-4bit-128g.safetensors
8b7d75d562938823c4503b956cb4b8af6ac0a5afbce2278566cc787da0f8f682  llama-30b-4bit-128g/llama-30b-4bit-128g.safetensors
f1418091e3307611fb0a213e50a0f52c80841b9c4bcba67abc1f6c64c357c850  llama-65b-4bit-128g/llama-65b-4bit-128g.safetensors
```

[Torrent source and more information](https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483941105)


## Alpaca quantized 4-bit weights ([GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) format with groupsize 128)

Model | Download
--- | ---
LLaMA 7B fine-tune from [ozcur/alpaca-native-4bit](https://huggingface.co/ozcur/alpaca-native-4bit) as safetensors | [2023-03-29 torrent magnet](magnet:?xt=urn:btih:90674fd4a3672c6eae5bf994634109bb75429e6b&dn=Alpaca-7B-GPTQ-4bit-128g-native-finetune_2023-03-29&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.skynetcloud.site%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.lelux.fi%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce)
LLaMA 33B merged with [baseten/alpaca-30b](https://huggingface.co/baseten/alpaca-30b) LoRA by [an anon](https://desuarchive.org/g/thread/92351574/#q92356537) | [2023-03-26 torrent magnet](magnet:?xt=urn:btih:81cf9b528cc80e390323f9ec50d4dfb4debcb490&dn=Alpaca%2030B%204bit%20groupsize%20128&tr=http%3A%2F%2Fbt2.archive.org%3A6969%2Fannounce) \| [extra config files](https://rentry.org/544p2#llama-33b)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/GPTQ-models-(4-bit-mode))

SHA256 checksums:
```text
17d6ba8f83be89f8dfa05cd4720cdd06b4d32c3baed79986e3ba1501b2305530  Alpaca-7B-GPTQ-4bit-128g-native-finetune_2023-03-29/alpaca-7b-4bit-128g-native-finetune.safetensors
a2f8d202ce61b1b612afe08c11f97133c1d56076d65391e738b1ab57c854ee05  Alpaca-30B-4bit-128g/alpaca-30b-hf-4bit.safetensors
```


## Vicuna 13B quantized 4-bit & 8-bit weights ([GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) format with groupsize 128)

#### [2023-04-03 torrent magnet](magnet:?xt=urn:btih:f67d372a01c0b8e0162931623d6c55a5e6f34921&dn=Vicuna-13B-quantized-128g&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/GPTQ-models-(4-bit-mode))

[Torrent source](https://desuarchive.org/g/thread/92531914#92536953)
[Extra config files](https://rentry.org/544p2#llama-13b)


## OpenAssistant LLaMA 13B WIP fine-tune quantized 4-bit weights ([GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) format with groupsize 128)

**Variant:** [dvruette/llama-13b-pretrained-dropout](https://huggingface.co/dvruette/llama-13b-pretrained-dropout)

#### [2023-04-11 torrent magnet](magnet:?xt=urn:btih:67fb68fe46b573b00d9b25bdf6cb363517e7b3cc&dn=dvruette_llama-13b-pretrained-dropout&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80&tr=udp%3a%2f%2fopen.tracker.cl%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/GPTQ-models-(4-bit-mode))

[Torrent source](https://desuarchive.org/g/thread/92694567/#q92697793)


## Alpacino 13B fine-tune 4-bit weights ([GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) format with groupsize 128)

**Variant:** [digitous/Alpacino13b](https://huggingface.co/digitous/Alpacino13b)

#### [HuggingFace Hub download](https://huggingface.co/gozfarb/alpacino-13b-4bit-128g/tree/main)

!!! info [Tutorial link for Text generation web UI](https://github.com/oobabooga/text-generation-webui/wiki/GPTQ-models-(4-bit-mode))